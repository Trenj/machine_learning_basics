{
	"nodes":[
		{"id":"d002ed8b997bb164","type":"file","file":"mhnoe/ml-labs/lab3/пр3.pdf","subpath":"#page=1","x":-410,"y":45,"width":820,"height":600},
		{"id":"f55a64099672e7a9","type":"file","file":"mhnoe/ml-labs/lab3/ТЗ - Лабораторная работа №3.md","x":-410,"y":-645,"width":820,"height":549},
		{"id":"c0fcdf6f3b37c006","x":1280,"y":-645,"width":683,"height":580,"type":"text","text":"```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n\niris = load_iris()\nX = iris.data\ny = iris.target\nfeature_names = iris.feature_names\ntarget_names = iris.target_names\n\n# стратифицированное разбиение\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\nprint(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n```"},
		{"id":"7e3a95c99197c4bc","x":1280,"y":87,"width":1240,"height":1115,"type":"text","text":"```python\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\n\n# дерево без ограничений (может переобучить)\ndt_full = DecisionTreeClassifier(random_state=42)\ndt_full.fit(X_train, y_train)\n\ntrain_acc = accuracy_score(y_train, dt_full.predict(X_train))\ntest_acc = accuracy_score(y_test, dt_full.predict(X_test))\nprint(\"Неограниченное дерево - train acc: {:.4f}, test acc: {:.4f}\".format(train_acc, test_acc))\n\n# Визуализация ограниченного примера дерева (ограничим глубину для наглядности)\nplt.figure(figsize=(12,6))\nplot_tree(dt_full, feature_names=feature_names, class_names=target_names, filled=True, max_depth=3)\nplt.title(\"Неограниченное дерево решений\")\nplt.show()\n```"},
		{"id":"98c19f21f60a47a4","x":1280,"y":1360,"width":840,"height":520,"type":"text","text":"```python\nfor params in [\n\t{\"max_depth\": 2},\n\t{\"max_depth\": 3},\n\t{\"max_depth\": 4},\n\t{\"min_samples_leaf\": 5},\n\t{\"min_samples_split\": 5}\n]:\n\n\tdt = DecisionTreeClassifier(random_state=42, **params)\n\tdt.fit(X_train, y_train)\n\n\tprint(f\"Params: {params} -> train_acc={accuracy_score(y_train, dt.predict(X_train)):.4f}, test_acc={accuracy_score(y_test, dt.predict(X_test)):.4f}\")\n```"},
		{"id":"08420326263ddaa2","x":1280,"y":2080,"width":1823,"height":1990,"type":"text","text":"```python\n# Ячейка: сравнение переобученного дерева и дерева с ограниченной глубиной (визуализация и accuracy)\n\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\nimport matplotlib.pyplot as plt\n\n# Предполагается, что X_train, y_train, X_test, y_test, feature_names, target_names уже определены\n\n# 1) уже обученное ранее дерево без ограничений (если нет — обучим его)\ndt_unrestricted = DecisionTreeClassifier(random_state=42)\ndt_unrestricted.fit(X_train, y_train)\n\n# 2) дерево с ограниченной глубиной (pruned / regularized)\nmax_depth_limited = 3 # можно изменить (2,3,4...)\ndt_limited = DecisionTreeClassifier(max_depth=max_depth_limited, random_state=42)\ndt_limited.fit(X_train, y_train)\n\n# Печатаем accuracy для сравнения\ntrain_acc_un = accuracy_score(y_train, dt_unrestricted.predict(X_train))\ntest_acc_un = accuracy_score(y_test, dt_unrestricted.predict(X_test))\ntrain_acc_lim = accuracy_score(y_train, dt_limited.predict(X_train))\ntest_acc_lim = accuracy_score(y_test, dt_limited.predict(X_test))\n\nprint(f\"Unrestricted tree -> train acc: {train_acc_un:.4f}, test acc: {test_acc_un:.4f}\")\nprint(f\"Limited tree (max_depth={max_depth_limited}) -> train acc: {train_acc_lim:.4f}, test acc: {test_acc_lim:.4f}\")\n\n# Рисуем два дерева рядом\nplt.figure(figsize=(18, 8))\n\nplt.subplot(1, 2, 1)\n\n# Показываем первые уровни переобученного дерева, чтобы график не был нечитаем\nplot_tree(dt_unrestricted, feature_names=feature_names, class_names=target_names, filled=True, max_depth=3)\nplt.title(\"Переобученное дерево\")\n\nplt.subplot(1, 2, 2)\n\n# Полная отрисовка ограниченного дерева (т.к. глубина маленькая, отрисовка читаема)\nplot_tree(dt_limited, feature_names=feature_names, class_names=target_names, filled=True)\nplt.title(f\"Обрезанное дерево (max_depth={max_depth_limited})\")\n\nplt.tight_layout()\nplt.show()\n```"},
		{"id":"a4289d9c8d58cc13","x":1280,"y":4300,"width":857,"height":933,"type":"text","text":"```python\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_estimators=100, random_state=42)\nrf.fit(X_train, y_train)\nprint(\"RandomForest (n_estimators=100) -> train acc: {:.4f}, test acc: {:.4f}\".format(\n\taccuracy_score(y_train, rf.predict(X_train)), accuracy_score(y_test, rf.predict(X_test))\n))\n\n# feature importances\nimportances = rf.feature_importances_\nfor name, imp in zip(feature_names, importances):\n\tprint(f\"{name}: {imp:.3f}\")\nplt.figure(figsize=(6,3))\nplt.barh(feature_names, importances)\nplt.title(\"Feature importances (RandomForest)\")\nplt.show()\n```"},
		{"id":"ffe9cba4615b37ee","x":1264,"y":5440,"width":1096,"height":720,"type":"text","text":"```python\nn_estimators_list = [1, 5, 10, 50, 100, 200]\nmax_depth_list = [None, 2, 3, 4, 5]\n\nresults = []\nfor n in n_estimators_list:\n\tfor d in max_depth_list:\n\t\trf = RandomForestClassifier(n_estimators=n, max_depth=d, random_state=42, n_jobs=-1)\n\t\trf.fit(X_train, y_train)\n\t\tresults.append((n, d, accuracy_score(y_train, rf.predict(X_train)), accuracy_score(y_test, rf.predict(X_test))))\n\n# Отобразим матрицу результатов (test accuracy)\nimport pandas as pd\ndf = pd.DataFrame(results, columns=[\"n_estimators\",\"max_depth\",\"train_acc\",\"test_acc\"])\npivot = df.pivot(index=\"n_estimators\", columns=\"max_depth\", values=\"test_acc\")\nprint(\"Test accuracy (rows: n_estimators, cols: max_depth):\")\n\n#display(pivot)\nprint(pivot)\n```"},
		{"id":"23544791ea73694a","x":1264,"y":6360,"width":989,"height":920,"type":"text","text":"```python\nfrom sklearn.ensemble import GradientBoostingClassifier\n\ngb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\ngb.fit(X_train, y_train)\nprint(\"GradientBoosting (100, lr=0.1, depth=3) -> train acc: {:.4f}, test acc: {:.4f}\".format(\naccuracy_score(y_train, gb.predict(X_train)), accuracy_score(y_test, gb.predict(X_test))\n))\n\n# feature importances\nimportances_gb = gb.feature_importances_\nfor name, imp in zip(feature_names, importances_gb):\n\tprint(f\"{name}: {imp:.3f}\")\nplt.figure(figsize=(6,3))\nplt.barh(feature_names, importances_gb)\nplt.title(\"Feature importances (GradientBoosting)\")\nplt.show()\n```"},
		{"id":"6ae21acbabbb4cee","x":1264,"y":7440,"width":1140,"height":682,"type":"text","text":"```python\nn_estimators_list = [10, 50, 100, 200, 500]\nlearning_rates = [0.01, 0.05, 0.1, 0.2]\n\nresults_gb = []\nfor lr in learning_rates:\n\tfor n in n_estimators_list:\n\t\tgb = GradientBoostingClassifier(n_estimators=n, learning_rate=lr, max_depth=3, random_state=42)\n\t\tgb.fit(X_train, y_train)\n\t\tresults_gb.append((lr, n, accuracy_score(y_train, gb.predict(X_train)), accuracy_score(y_test, gb.predict(X_test))))\n\nimport pandas as pd\ndf_gb = pd.DataFrame(results_gb, columns=[\"learning_rate\",\"n_estimators\",\"train_acc\",\"test_acc\"])\npivot_gb = df_gb.pivot(index=\"n_estimators\", columns=\"learning_rate\", values=\"test_acc\")\nprint(\"GradientBoosting test accuracy (rows: n_estimators, cols: learning_rate):\")\n\n#display(pivot_gb)\nprint(pivot_gb)\n```"}
	],
	"edges":[
		{"id":"aa5fe815b970abbf","fromNode":"c0fcdf6f3b37c006","fromSide":"bottom","toNode":"7e3a95c99197c4bc","toSide":"top"},
		{"id":"10cecb7b89774c0f","fromNode":"7e3a95c99197c4bc","fromSide":"bottom","toNode":"98c19f21f60a47a4","toSide":"top"},
		{"id":"0938421655694ab9","fromNode":"98c19f21f60a47a4","fromSide":"bottom","toNode":"08420326263ddaa2","toSide":"top"},
		{"id":"a87cba32b408cf06","fromNode":"08420326263ddaa2","fromSide":"bottom","toNode":"a4289d9c8d58cc13","toSide":"top"},
		{"id":"0b9a4ad22d8c2677","fromNode":"a4289d9c8d58cc13","fromSide":"bottom","toNode":"ffe9cba4615b37ee","toSide":"top"},
		{"id":"b21e158a775da71d","fromNode":"ffe9cba4615b37ee","fromSide":"bottom","toNode":"23544791ea73694a","toSide":"top"},
		{"id":"3237512f1d302b34","fromNode":"23544791ea73694a","fromSide":"bottom","toNode":"6ae21acbabbb4cee","toSide":"top"}
	]
}